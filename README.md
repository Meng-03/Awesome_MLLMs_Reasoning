# Awesome_MLLMs_Reasoning

In this repository, we will continuously update the latest papers, slides, and other valuable resources that advance MLLM reasoning, making learning more efficient for everyone!

## Papers

### Generated Data Guided Post-Training
[2503] [Visual-RFT: Visual Reinforcement Fine-Tuning](https://arxiv.org/abs/2503.01785) (Shanghai AI Lab)   [Code](https://github.com/Liuziyu77/Visual-RFT)

[2502] [OmniAlign-V](https://arxiv.org/pdf/2502.18411)  [Code]()

[2502] [Visual Perception Tokens](https://arxiv.org/pdf/2502.17425)  [Code]()

[2502] [MM-Verify](https://arxiv.org/pdf/2502.13383)  [Code]()

[2502] [MM-RLHF](https://arxiv.org/pdf/2502.10391)  [Code]()

[2502] [MedVLM-R1](https://arxiv.org/pdf/2502.19634)  [Code]()

[2501] [PARM++](https://arxiv.org/pdf/2501.13926)  [Code]()

[2501] [Kimi k1.5](https://arxiv.org/pdf/2501.12599)  [Code]()

[2501] [URSA](https://arxiv.org/pdf/2501.04686)  [Code]()

[2501] [LlamaV-o1](https://arxiv.org/pdf/2501.06186)  [Code]()

[2501] [MVoT](https://arxiv.org/pdf/2501.07542)  [Code]()

[2501] [Virgo](https://arxiv.org/pdf/2501.01904)  [Code]() 

[2412] [MAmmoTH-VL](https://arxiv.org/pdf/2412.05237)  [Code]()

[2412] [Mulberry](https://arxiv.org/pdf/2412.03704)  [Code]()

[2412] [TACO](https://arxiv.org/pdf/2412.05479)  [Code]()

[2412] [M-Star](https://arxiv.org/pdf/2412.17451)  [Code]()

[2412] [AR-MCTS](https://arxiv.org/pdf/2412.14835)  [Code]()

[2411] [InternVL2-8B-MPO](https://arxiv.org/pdf/2411.10442)  [Code]()

[2411] [Critic-V](https://arxiv.org/pdf/2411.18203)  [Code]()

[2411] [Insight-V](https://arxiv.org/pdf/2411.14432)  [Code]()

[2411] [AtomThink](https://arxiv.org/pdf/2411.11930)  [Code]()

[2411] [LLaVA-o1](https://arxiv.org/pdf/2411.10440v1)  [Code]()

[2411] [R3V](https://arxiv.org/pdf/2411.00855)  [Code]()

[2403] [Visual-CoT](https://arxiv.org/pdf/2403.16999)  [Code]()

[2306] [Shikra](https://arxiv.org/pdf/2306.15195)  [Code]() 


### Test-time Scaling
[2502] [ASTAR](https://arxiv.org/pdf/2502.02339)  [Code]()

[2502] [MLLMS KNOW WHERE TO LOOK](https://arxiv.org/pdf/2502.17422)  [Code]()

[2412] [VisVM](https://arxiv.org/pdf/2412.03704)  [Code]()

[2412] [Mulberry](https://arxiv.org/pdf/2412.03704)  [Code]()

[2409] [FAST](https://openreview.net/pdf?id=ncCuiD3KJQ)  [Code]()

[2411] [R3V](https://arxiv.org/pdf/2411.00855)  [Code]()

[2402] [Scaffold](https://arxiv.org/pdf/2402.12058)  [Code]()

[2402] [vstar](https://arxiv.org/pdf/2402.06457)  [Code]() 

### Benchmarks
[2502] [Multimodal RewardBench](https://arxiv.org/pdf/2502.14191)  [Code](https://github.com/facebookresearch/multimodal_rewardbench)

[2502] [Zero-Bench](https://arxiv.org/pdf/2502.09696)  [Code](https://zerobench.github.io/)

[2502] [MM-IQ](https://arxiv.org/pdf/2502.00698)  [Code](https://acechq.github.io/MMIQ-benchmark/)

[2502] [MME-CoT](https://arxiv.org/pdf/2502.09621)  [Code](https://mmecot.github.io/)

[2406] [Cambrian-1 (CV-Bench)](https://arxiv.org/pdf/2406.16860)  [Code](https://github.com/cambrian-mllm/cambrian)

[2404] [BLINK](https://arxiv.org/pdf/2404.12390)  [Code]()

[2401] [MMVP](https://arxiv.org/pdf/2401.06209)  [Code]()

[2312] [Vâˆ—](https://arxiv.org/pdf/2312.14135)  [Code]() 

### MLLM Reward Model Design

## Projects
[R1-V](https://github.com/Deep-Agent/R1-V) 
